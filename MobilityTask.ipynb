{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DM - Mobility Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team members:\n",
    " * Frick Bernhard (a01505541@unet.univie.ac.at)\n",
    " * Postlmayr Billie Rosalie (a01307120@unet.univie.ac.at)\n",
    "\n",
    "Former team members that opted out of the course:\n",
    " * Decsi IstvÃ¡n (a11834026@unet.univie.ac.at)\n",
    " * Krivanek Yvonne-Nadine (a01404589@unet.univie.ac.at)\n",
    "\n",
    "Tokens:\n",
    " * Frick: dm19_byrzma (id: 35)\n",
    " * Postlmayr: dm19_postlmayr (id: 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import mplleaflet\n",
    "import re\n",
    "import dateutil.parser\n",
    "from matplotlib.dates import date2num\n",
    "from IPython.display import display, HTML\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing non-whitelisted trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for wrongly annotated trips, we used a whitelist where we listed all trips that are correctly annotated:\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/11Ta24L86uB1UiKwSa5of5MKfUIaoXxq53kGWQ8U-AyI/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist_ids = {\n",
    "    5, 46, 74, 127, 128, 129, 131, 165, 99, 105,\n",
    "    107, 108, 109, 152, 202, 203, 13, 28, 43, 52,\n",
    "    145, 146, 22, 24, 26, 42, 102, 103, 147, 214,\n",
    "    215, 19, 134, 137, 139, 142, 220, 222, 223, 224,\n",
    "    26, 248, 246, 245, 241, 84, 93, 235, 236, 33,\n",
    "    36, 37, 40, 49, 120, 113, 114, 115, 116, 117,\n",
    "    218, 219, 226, 227, 240, 21, 32, 38, 70, 95,\n",
    "    199, 78, 82, 83, 160, 161, 208, 209, 55, 9,\n",
    "    35, 88, 210, 211, 217, 72, 47, 201, 204, 91,\n",
    "    110, 228, 233, 234, 237\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of whitelisted trips:\", len(whitelist_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_trips(trip):\n",
    "    # skip files that are not a trip\n",
    "    if re.search(\"^\\d+_\\d+_\\d{4}-\\d{2}-\\d{2}T\\d{6}\\.\\d{1,3}$\", trip) is None:\n",
    "        return False\n",
    "\n",
    "    # extract the trip id\n",
    "    trip_id = int(trip.split('_')[1])\n",
    "    \n",
    "    # keep trips that are whitelisted\n",
    "    if trip_id in whitelist_ids:\n",
    "        return True\n",
    "    \n",
    "    # otherwise: skip the trip\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelisted_trips = list(filter(filter_trips, all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict: trip-id -> folder name\n",
    "all_trips = dict(map(lambda trip: (int(trip.split('_')[1]), trip), whitelisted_trips))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Our Trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script puts out data about the following data for a given list of trips:\n",
    " * The trip ID\n",
    " * The duration of the trip\n",
    " * A table with all markers\n",
    " * A plot with the acceleration data and markers\n",
    " * A plot of the location data of the trip\n",
    "\n",
    "To plot the location data, we used https://github.com/jwass/mplleaflet, a wrapper for pyplot and openstreetmap.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trip_folders(ids):\n",
    "    return dict(filter(lambda elem: elem[0] in ids, all_trips.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trip_overview(trips):\n",
    "    print(\"Number of trips: \", len(trips))\n",
    "    \n",
    "    trips = get_trip_folders(trips)\n",
    "\n",
    "    for tid, trip in trips.items():\n",
    "\n",
    "        display(HTML(f\"<h1>Trip id {tid}</h1>\".format(tid)))\n",
    "\n",
    "        # read markers file\n",
    "        marker_col_names = [\"time\", \"key\", \"value\", \"mode\", \"longitude\", \"latitude\", \"col7\", \"col8\", \"col9\"]\n",
    "        markers = pd.read_csv(os.path.join(\"data\", trip, \"markers.csv\"), sep=';', names=marker_col_names, skiprows=1)\n",
    "\n",
    "        # total duration\n",
    "        start = dateutil.parser.parse(markers.loc[markers.index[0], 'time'])\n",
    "        stop = dateutil.parser.parse(markers.loc[markers.index[-1], 'time'])\n",
    "        print(\"Duration:\", stop-start)\n",
    "\n",
    "        # print markers table\n",
    "        mode_changes = markers[markers[\"key\"] == \"CGT_MODE_CHANGED\"]\n",
    "        display(HTML(mode_changes.to_html()))\n",
    "\n",
    "        # prepare acceleration data for plot\n",
    "        acceleration = pd.read_csv(os.path.join(\"data\", trip, \"acceleration.csv\"))\n",
    "        acceleration['time'] = date2num(pd.to_datetime(acceleration['time']))\n",
    "        acceleration['acc_norm'] = np.linalg.norm(acceleration[['x', 'y', 'z']].values, axis=1)\n",
    "        acceleration = acceleration.drop(['x', 'y', 'z'], axis=1)\n",
    "\n",
    "        # plot acceleration data\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.grid(True)\n",
    "        plt.plot_date(acceleration['time'], acceleration['acc_norm'], linewidth=1, color='black', linestyle='solid', marker='None')\n",
    "\n",
    "        max_acc = np.max(acceleration['acc_norm'])\n",
    "\n",
    "        # markers for acceleration data\n",
    "        for index, row in mode_changes.iterrows():\n",
    "            x = date2num(pd.to_datetime(row[\"time\"]))\n",
    "            # vertical line\n",
    "            plt.axvline(x=x)\n",
    "            # mode text\n",
    "            plt.text(x=x, y=max_acc*.95, s=row[\"mode\"], rotation=90, fontsize=16)\n",
    "        plt.show()\n",
    "\n",
    "        # plot map with location data\n",
    "        positions = pd.read_csv(os.path.join(\"data\", trip, \"positions.csv\"))\n",
    "        positions = positions[positions[\"location_source\"] == 1]\n",
    "        positions = positions.filter(items=['longitude', 'latitude'])\n",
    "        plt.figure(figsize=(20,8))\n",
    "        plt.plot(positions['longitude'], positions['latitude'], 'r.', markersize=4)\n",
    "        display(mplleaflet.display())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernhard Frick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frick_trip_ids = {113, 114, 115, 116, 117, 218, 219, 226, 227, 240}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trip_overview(frick_trip_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Billie Rosalie Postlmayr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postlmayr_trip_ids = {84, 93, 235, 236}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trip_overview(postlmayr_trip_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script loops over all whitelisted trips and performs the following preprocessing steps:\n",
    "\n",
    " * Calculating the norm of the x, y and z dimensions of the acceleration data\n",
    " * Downsampling the acceleration data\n",
    " * Removing bimodal segments\n",
    " * Combining all segments into one file (`export.csv`)\n",
    "\n",
    "`export.csv` is then in turn used by the next script to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Split each trip into segments of 10 seconds (after preprocessing steps this should be a 1-dimensional time series of 10 * 10 = 100 observations). Skip segments that are\n",
    "a. shorter than 10 seconds (typically the last segment of a trip), or\n",
    "b. bimodal (segments covering two transport modes, at the change of the transport mode)\n",
    "\n",
    "Looks like our data is resampled to ms?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_date(s):\n",
    "    return s.group(0).replace('Z', '') + '.000Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(m):\n",
    "    m = [re.sub(r':\\d\\d+Z', replace_date, sample) for sample in m]\n",
    "    m = [float(datetime.strptime(sample, \"%Y-%m-%dT%H:%M:%S.%fZ\").strftime('%s.%f')) for sample in m]\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed = None\n",
    "\n",
    "processed_count = 0\n",
    "total_trips = len(whitelisted_trips)\n",
    "\n",
    "for trip in whitelisted_trips:\n",
    "    user_id = re.search('\\d+', trip).group(0)\n",
    "    trip_id = re.search('_\\d+_', trip).group(0)\n",
    "    trip_id = re.search('\\d+', trip_id).group(0)\n",
    "\n",
    "    processed_count = processed_count + 1\n",
    "    print(\"processing user: \", user_id, \", trip: \", trip_id, \" --- (\", processed_count, \"/\", total_trips, \")\")\n",
    "    \n",
    "    # markers\n",
    "    path_markers = os.path.join(data_dir, trip, 'markers.csv')\n",
    "    col_names = [\"value\", \"key\", \"time\", \"mode\", \"col5\", \"col6\", \"col7\", \"station\", \"col9\"]\n",
    "    markers = pd.read_csv(path_markers, sep=';', names=col_names, skiprows=4)\n",
    "    markers = markers.drop(['value', 'key', 'col5', 'col6', 'col7', 'col9'], axis=1)\n",
    "    markers.drop(markers.tail(1).index, inplace=True)\n",
    "\n",
    "    # acceleration\n",
    "    path_acc = os.path.join(data_dir, trip, 'acceleration.csv')\n",
    "    acceleration = pd.read_csv(path_acc, sep=',')\n",
    "    acceleration['acc_norm'] = np.linalg.norm(acceleration[['x', 'y', 'z']].values, axis=1)\n",
    "    acceleration = acceleration.drop(['x', 'y', 'z'], axis=1)\n",
    "\n",
    "    # activity\n",
    "#    path_activity = os.path.join(data_dir, trip, 'activity_records.csv')\n",
    "#    activity = pd.read_csv(path_activity, sep=',')\n",
    "\n",
    "    # time formatting\n",
    "    acceleration['time'] = format_time(acceleration['time'])\n",
    "    acceleration['time'] = acceleration['time'].astype(int)\n",
    "    markers['time'] = format_time(markers['time'])\n",
    "    markers['time'] = markers['time'].astype(int)\n",
    "\n",
    "    # downsample\n",
    "    acceleration = acceleration.set_index(['time'])\n",
    "    acceleration.index = pd.to_datetime(acceleration.index, unit='ms')\n",
    "    acceleration = acceleration.resample('1L').mean()\n",
    "    markers = markers.set_index(['time'])\n",
    "    markers.index = pd.to_datetime(markers.index, unit='ms')\n",
    "\n",
    "    # combine acceleration and markers\n",
    "    df_trip = acceleration.merge(markers, on=\"time\", how='left')\n",
    "    df_trip = df_trip.ffill()\n",
    "\n",
    "    # eliminate bimodal segments\n",
    "    df_trip = df_trip.reset_index()\n",
    "    drop_multimodal = []\n",
    "    for i in range(int(df_trip.shape[0] / 10)):\n",
    "        counts = df_trip.iloc[i * 10:i * 10 + 10].groupby('mode').count()\n",
    "        if counts.shape[0] != 1:\n",
    "            for val in range(i * 10, i * 10 + 10):\n",
    "                drop_multimodal.append(val)\n",
    "    df_trip.drop(drop_multimodal, inplace=True)\n",
    "\n",
    "    # add ids and add to overall dataframe\n",
    "    df_trip['user_id'] = user_id\n",
    "    df_trip['trip_id'] = trip_id\n",
    "    if processed is None:\n",
    "        processed = df_trip.copy()\n",
    "    else:\n",
    "        processed = processed.append(df_trip, ignore_index=True, sort=False)\n",
    "\n",
    "processed = processed.set_index(['time'])\n",
    "processed.to_csv('export.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set consists of 94 trips by 17 students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = pd.read_csv(os.path.join(\"export.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessed data consists of the following entry counts per transportation mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = export.groupby('mode').agg(['count']).stack()['time']\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = counts/export.count()['time']\n",
    "percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the different transportation modes are nearly indistinguishable when only considering the mean, std and quartiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for mode in export['mode'].unique():\n",
    "    print(\"Mode:\", mode)\n",
    "    mode_norm = export[export['mode'] == mode]['acc_norm']\n",
    "    desc = mode_norm.describe().drop('count')\n",
    "    desc['median'] = mode_norm.median()\n",
    "    print(desc)\n",
    "    plt.plot(desc, label=mode, marker='o', linestyle='none')\n",
    "    print()\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Single Classifier model (SCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report the following performance measures:\n",
    " * accuracy\n",
    " * precision (macro and weighted)\n",
    " * recall (macro and weighted)\n",
    " * F1-scores (macro and weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(y_true, y_pred, labels=[]) # labels: per label precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble Walk Classifier model (EWCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report the following performance measures:\n",
    " * accuracy\n",
    " * precision (macro and weighted)\n",
    " * recall (macro and weighted)\n",
    " * F1-scores (macro and weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sources\n",
    "\n",
    " * https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/\n",
    " * https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
